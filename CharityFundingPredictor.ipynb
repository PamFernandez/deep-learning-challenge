{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 12 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 10 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(['EIN', 'NAME'], axis=1, inplace=True)\n",
    "application_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Target variable</b> = IS_SUCCESSFUL -- 1 is considered yes (successful) and 0 is considered no (not successful)\n",
    "\n",
    "<b>Features</b> = there are 9 features - all the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "app_cat = application_df.dtypes.index.tolist()\n",
    "application_df[app_cat].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_type_count = application_df['APPLICATION_TYPE'].value_counts()\n",
    "app_type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Other      804\n",
       "T8         737\n",
       "T7         725\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = list(app_type_count[app_type_count < 600].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_count = application_df['CLASSIFICATION'].value_counts()\n",
    "class_count.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1484\n",
       "C7000      777\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = list(class_count[class_count < 300].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                       1   \n",
       "1           1    108590              1                       0   \n",
       "2           1      5000              0                       0   \n",
       "3           1      6692              1                       0   \n",
       "4           1    142590              1                       0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                       0   \n",
       "34295       1      5000              0                       0   \n",
       "34296       1      5000              0                       0   \n",
       "34297       1      5000              1                       0   \n",
       "34298       1  36500179              0                       0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                         0                    0                    0   \n",
       "1                         0                    1                    0   \n",
       "2                         0                    0                    0   \n",
       "3                         0                    1                    0   \n",
       "4                         0                    1                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "34294                     0                    0                    1   \n",
       "34295                     0                    0                    1   \n",
       "34296                     0                    1                    0   \n",
       "34297                     0                    0                    0   \n",
       "34298                     0                    1                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                        0                    0                    0  ...   \n",
       "1                        0                    0                    0  ...   \n",
       "2                        1                    0                    0  ...   \n",
       "3                        0                    0                    0  ...   \n",
       "4                        0                    0                    0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                    0                    0                    0  ...   \n",
       "34295                    0                    0                    0  ...   \n",
       "34296                    0                    0                    0  ...   \n",
       "34297                    1                    0                    0  ...   \n",
       "34298                    0                    0                    0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                      0                       0                         0   \n",
       "1                      1                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       1                         0   \n",
       "4                      0                       0                         1   \n",
       "...                  ...                     ...                       ...   \n",
       "34294                  0                       0                         0   \n",
       "34295                  0                       0                         0   \n",
       "34296                  0                       0                         0   \n",
       "34297                  0                       0                         0   \n",
       "34298                  0                       0                         0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                       0                 0                       0   \n",
       "1                       0                 0                       0   \n",
       "2                       0                 0                       0   \n",
       "3                       0                 0                       0   \n",
       "4                       0                 0                       0   \n",
       "...                   ...               ...                     ...   \n",
       "34294                   0                 0                       0   \n",
       "34295                   0                 0                       0   \n",
       "34296                   0                 0                       0   \n",
       "34297                   0                 0                       0   \n",
       "34298                   0                 1                       0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                    0                  0                         1   \n",
       "1                    0                  0                         1   \n",
       "2                    0                  0                         1   \n",
       "3                    0                  0                         1   \n",
       "4                    0                  0                         1   \n",
       "...                ...                ...                       ...   \n",
       "34294                0                  0                         1   \n",
       "34295                0                  0                         1   \n",
       "34296                0                  0                         1   \n",
       "34297                0                  0                         1   \n",
       "34298                0                  0                         1   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "...                         ...  \n",
       "34294                         0  \n",
       "34295                         0  \n",
       "34296                         0  \n",
       "34297                         0  \n",
       "34298                         0  \n",
       "\n",
       "[34299 rows x 44 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "numeric_app_df = pd.get_dummies(application_df)\n",
    "numeric_app_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = numeric_app_df[\"IS_SUCCESSFUL\"]\n",
    "X = numeric_app_df.drop([\"IS_SUCCESSFUL\"],axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile, Train and Evaluate the Model\n",
    "\n",
    "## Attempt #1<br>\n",
    "APPLICATION_TYPE cutoff = 600<br>\n",
    "CLASSIFICATION cutoff = 300<br>\n",
    "layer1 = 9 : activation function = relu<br>\n",
    "layer2 = 18 : activation function = relu<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# number_input_features = len(X_train_scaled[0])\n",
    "# hidden_nodes_layer1 = 9\n",
    "# hidden_nodes_layer2 = 18\n",
    "\n",
    "# nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "# nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "# nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "# y_test = np.array(y_test)\n",
    "# y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "# fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "# model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the accuracy\n",
    "# history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "# history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "# nn.save('Models/AlphabetSoupCharity1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "<b>This is Attempt #1</b>\n",
    "<br>APPLICATION_TYPE cutoff = 600\n",
    "<br>CLASSIFICATION cutoff = 300\n",
    "<br>layer1 = 9 : activation function = relu\n",
    "<br>layer2 = 18 : activation function = relu\n",
    "\n",
    "Loss: 0.5536191259042167, Accuracy: 0.727580189704895\n",
    "\n",
    "A loss value of 55 indicates that the model can be further optimized. \n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "I need to make some changes in order to get to 75% accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "\n",
    "<br>APPLICATION_TYPE cutoff = 600\n",
    "<br>CLASSIFICATION cutoff = 300\n",
    "<br>layer1 = 12\n",
    "<br>layer2 = 24\n",
    "\n",
    "Loss: 0.5522796763553564, Accuracy: 0.7250145673751831\n",
    "\n",
    "\n",
    "<br>APPLICATION_TYPE cutoff = 800\n",
    "<br>CLASSIFICATION cutoff = 1000\n",
    "<br>layer1 = 12\n",
    "<br>layer2 = 24\n",
    "\n",
    "Loss: 0.5575985619278065, Accuracy: 0.7231487035751343\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt #2 -- adding a hidden layer\n",
    "APPLICATION_TYPE cutoff = 600<br>\n",
    "CLASSIFICATION cutoff = 300<br>\n",
    "layer1 = 9 : activation function = relu<br>\n",
    "layer2 = 18 : activation function = relu<br>\n",
    "layer3 = 27 : activation function = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 9)                 396       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 27)                513       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 1,117\n",
      "Trainable params: 1,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 9\n",
    "hidden_nodes_layer2 = 18\n",
    "hidden_nodes_layer3 = 27\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 6s 241us/sample - loss: 0.5865 - accuracy: 0.7059\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 8s 293us/sample - loss: 0.5584 - accuracy: 0.7293\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5558 - accuracy: 0.7301\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5531 - accuracy: 0.7328\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5520 - accuracy: 0.7320\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5511 - accuracy: 0.7316\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5500 - accuracy: 0.7329\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5496 - accuracy: 0.7336\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5488 - accuracy: 0.7331\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.5486 - accuracy: 0.7334\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5481 - accuracy: 0.7338\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5480 - accuracy: 0.7328\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5475 - accuracy: 0.7334\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5472 - accuracy: 0.7328\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 0.5468 - accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 5s 200us/sample - loss: 0.5466 - accuracy: 0.7340\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5463 - accuracy: 0.7343\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5460 - accuracy: 0.7334\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 5s 205us/sample - loss: 0.5465 - accuracy: 0.7336\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 4s 168us/sample - loss: 0.5455 - accuracy: 0.7352\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5457 - accuracy: 0.7341\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.5457 - accuracy: 0.7350\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5453 - accuracy: 0.7338\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.5447 - accuracy: 0.7348\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.5447 - accuracy: 0.7344\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5448 - accuracy: 0.7349\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5447 - accuracy: 0.7342\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5449 - accuracy: 0.7348\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5445 - accuracy: 0.7349\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5445 - accuracy: 0.7359\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5444 - accuracy: 0.7360\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5440 - accuracy: 0.7355\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5436 - accuracy: 0.7350\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5436 - accuracy: 0.7354\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5435 - accuracy: 0.7359\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5437 - accuracy: 0.7350\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5435 - accuracy: 0.7364\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5430 - accuracy: 0.7357\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.5431 - accuracy: 0.7353\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5432 - accuracy: 0.7362\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5427 - accuracy: 0.7356\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5426 - accuracy: 0.7351\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5429 - accuracy: 0.7350\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5423 - accuracy: 0.7364\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5425 - accuracy: 0.7357\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5428 - accuracy: 0.7369\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5423 - accuracy: 0.7373\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5422 - accuracy: 0.7363\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5423 - accuracy: 0.7364\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5419 - accuracy: 0.7364\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5418 - accuracy: 0.7374\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5420 - accuracy: 0.7368\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5419 - accuracy: 0.7363\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5420 - accuracy: 0.7373\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.5416 - accuracy: 0.7361\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5413 - accuracy: 0.7374\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5413 - accuracy: 0.7368\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5412 - accuracy: 0.7376\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5414 - accuracy: 0.7375\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5414 - accuracy: 0.7374\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5409 - accuracy: 0.7379\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5411 - accuracy: 0.7379\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5410 - accuracy: 0.7373\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5413 - accuracy: 0.7373\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5409 - accuracy: 0.7362\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5406 - accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.5410 - accuracy: 0.7375\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5407 - accuracy: 0.7362\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5409 - accuracy: 0.7379\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5408 - accuracy: 0.7373\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5407 - accuracy: 0.7371\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5406 - accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5404 - accuracy: 0.7380\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5400 - accuracy: 0.7375\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5404 - accuracy: 0.7376\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5406 - accuracy: 0.7372\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5401 - accuracy: 0.7367\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5402 - accuracy: 0.7360\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.5396 - accuracy: 0.7379\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5402 - accuracy: 0.7381\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5400 - accuracy: 0.7374\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5403 - accuracy: 0.7382\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5398 - accuracy: 0.7377\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5396 - accuracy: 0.7388\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5398 - accuracy: 0.7375\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5399 - accuracy: 0.7374\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5396 - accuracy: 0.7382\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5401 - accuracy: 0.7371\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5399 - accuracy: 0.7376\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5401 - accuracy: 0.7381\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5397 - accuracy: 0.7378\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 0.5396 - accuracy: 0.7383\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5391 - accuracy: 0.7381\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5397 - accuracy: 0.7379\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5396 - accuracy: 0.7376\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5395 - accuracy: 0.7379\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5390 - accuracy: 0.7380\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5396 - accuracy: 0.7385\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5393 - accuracy: 0.7367\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5392 - accuracy: 0.7376\n"
     ]
    }
   ],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 0s - loss: 0.5816 - accuracy: 0.7258\n",
      "Loss: 0.5534283416889847, Accuracy: 0.7258309125900269\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f993facd6d0>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD6CAYAAACoCZCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV5f3A8c83izDDCjNA2BsChCGoDFFBGWK1gmIRV1GwdVdbbbXW1mpx1Kr8cIGjUBUHVYoMFQTZmxBCQlhhJcwQIMkd398f9ybcLHLBsHK+79frvu495zzn3PNEfL73fM/zPEdUFWOMMc4TcqFPwBhjzIVhAcAYYxzKAoAxxjiUBQBjjHEoCwDGGONQFgCMMcahggoAIjJIRJJEJEVEnihm+2Mistb/2igiHhGpGbA9VETWiMjXAetqishcEUn2v9comyoZY4wJhpQ2DkBEQoEtwNVAGrACGKWqm0ooPxR4SFUHBKx7GIgHqqnqEP+6F4FDqvqCP6jUUNXfne5cateurbGxscHWzRhjDLBq1aoDqhpdeH1YEPv2AFJUNRVARKYDw4FiAwAwCpiWtyAiMcD1wPPAwwHlhgP9/J+nAj8Apw0AsbGxrFy5MohTNsYYk0dEdhS3PpgUUENgV8Bymn9dcV9SCRgEzAhY/SrwOOAtVLyuqu4F8L/XCeJcjDHGlJFgAoAUs66kvNFQYLGqHgIQkSFAuqquOsvzQ0TuFZGVIrIyIyPjbA9jjDGmkGACQBrQKGA5BthTQtmRBKR/gD7AMBHZDkwHBojIR/5t+0WkPoD/Pb24A6rqZFWNV9X46OgiKSxjjDFnKZh7ACuAliLSFNiNr5G/tXAhEYkC+gKj89ap6pPAk/7t/YBHVTVv+0xgDPCC//2rs6mAy+UiLS2N7Ozss9nd8SIjI4mJiSE8PPxCn4ox5jwrNQCoqltEJgDfAqHAe6qaICLj/Nsn+YuOAOao6vEgv/sF4BMRuQvYCdx8xmcPpKWlUbVqVWJjYxEpLltlSqKqHDx4kLS0NJo2bXqhT8cYc56V2g30YhIfH6+FewElJibSpk0ba/zPkqqyefNm2rZte6FPxRhzjojIKlWNL7y+XIwEtsb/7NnfzhjnKhcBwBhjinMwK4dPVuziUsp0nE/B3AQ2xphL0ouzk/jPyl3E1KhI7xa1L/TpXHTsCuAS4na7L/QpGHPJ2Hc0m8/XpAHw0bJiB8JeVFLSj/H6/GRcnsJjZs8dCwBl5IYbbqBbt260b9+eyZMnAzB79my6du1K586dueqqqwDIyspi7NixdOzYkU6dOjFjhm/QdJUqVfKP9dlnn3HHHXcAcMcdd/Dwww/Tv39/fve737F8+XJ69+5Nly5d6N27N0lJSQB4PB4effTR/OO+/vrrzJ8/nxEjRuQfd+7cudx4443n489hzHnl8nhJP1awK/i7i1LxKlzXsR5zEvaTnln2XcW9XuW1eclMnJNU5PvPxKodh/jFW0uYOHcLP209WIZneHrlKgX07H8T2LQns0yP2a5BNf40tH2p5d577z1q1qzJyZMn6d69O8OHD+eee+5h4cKFNG3alEOHDgHw3HPPERUVxYYNGwA4fPhwqcfesmUL8+bNIzQ0lMzMTBYuXEhYWBjz5s3j97//PTNmzGDy5Mls27aNNWvWEBYWxqFDh6hRowbjx48nIyOD6Oho3n//fcaOHfvz/iDGXCAZx3J464etRFUM57cDWxbY9sC/1/B9Ujof3NmDns1qceRELv9etpOhnerz4MBWzNqwj+krdvGbq1oWOW7CnqOM/3g1/7i5M/GxNYtsB19vuU9W7qJxzcpc1rwWALluL498uo7/rvONi/2/Banc2LUhI3s0pn2DaoSHBvf7+vvN6dz38SrqVYsk1+1lfuJ++rY6P4Ney1UAuJD++c9/8sUXXwCwa9cuJk+ezJVXXpnfv75mTd8/rHnz5jF9+vT8/WrUKH0W7JtvvpnQ0FAAjh49ypgxY0hOTkZEcLlc+ccdN24cYWFhBb7v9ttv56OPPmLs2LEsWbKEDz74oIxqbC4WJ3M9vPlDCgeP5wIQHiKM6R1Ls+gqpewZvBO5brYdOE77BlFBld995CRPfbGBB65qSdfGP2+m98xsF28vTOXdRds4kesBoE39qlzbvh4A3ybsY3bCPipHhHLX1JVMu6cXPySlczzXw7h+zYmtXZkrWtZm2vKd3N+vOWEBDbPL4+XRT9ez/eAJXpufzId39Szy/W6Plyc+38Bnq3zppCtbRfPAgBb8c34yPyYf4InBbbi2fT3e+TGVz1alMX3FLiLDQ+gcU51BHerxq8tiCQ051dsuPTObbzftZ2t6FqkHjrM45QDt6lfj/bHdefLzDcxPTOfZYXpeeuiVqwAQzC/1c+GHH35g3rx5LFmyhEqVKtGvXz86d+6cn54JpFr8f9jAdYVHNVeuXDn/89NPP03//v354osv2L59O/369TvtcceOHcvQoUOJjIzk5ptvzg8Qpnw4kevmzikrWLbtELUqVwB8DeYPWzKYOeFyoiqWzQjvv83azEfLdvDOr+K5qm3dUstPnJPE90kZrNh+mKl3dqdbk+J/WQfj/o9WsyjlAEM61ee3V7Xkwf+s5cnPN9C1cQ0qRoTyzMwE2tSrytu/imfk5KX86r1lAAxoU4c29aoBMLpXE3794Sq+25zONf7AATDph60k7s3k8ha1+TH5AJv2ZNKuQbX87SdzPTwwbTXzEtP5zYAWVI0M540fUrh50hJCBF68qRO/jPfNlPP8iI48ck1rftp6gFU7DrN82yGe/e8m/rtuDxN/GUejGhWZumQHr8zdQlaOm0oRoTStXZmR3Rvx5HVtqVIhjKva1GHupv0k7T+Wf+7nkt0DKANHjx6lRo0aVKpUic2bN7N06VJycnJYsGAB27ZtA8hPAV1zzTX861//yt83LwVUt25dEhMT8Xq9+VcSJX1Xw4a+yVinTJmSv/6aa65h0qRJ+TeK876vQYMGNGjQgL/85S/59xXMpePoSRfv/JjK1+v3sGlPJif9v4ABjue4ueP9FSzfdohXb4lj5VMDWfnUQP59d092Hz7Jo5+uK5Puj16v8m3CPlTht9PXkrz/2GnLb9l/jC/W7OambjHUqVqBX727nBXbD3Ey18Oy1IN8uGQ7u4+cDOq7j5zI5aetBxjfvzn/urUrLetW5dVb4sjKcfPk5+uZOCeJfZnZPD+iI41qVuLju3sSGhLC4RMu7u/XPP84V7WpQ/2oSD5atrPAef7zu2SGdKrPG7d2pVJEKO/8mJq//WSuhzHvLWf+5nSeG96eh69pzT1XNmPh4/157NrWvD+2R37jn6dm5QiGdGrAn4a25+sHLue1kXGkpGcx+LWFDHrtR577ehPdmtRgzkNXkvDstXzzmyt4fkRHqlTw/TAb0MY3KfL8xFNTo2W7PDz/zaafdY+hJPZzsAwMGjSISZMm0alTJ1q3bk2vXr2Ijo5m8uTJ3HjjjXi9XurUqcPcuXN56qmnGD9+PB06dCA0NJQ//elP3HjjjbzwwgsMGTKERo0a0aFDB7Kysor9rscff5wxY8bw8ssvM2BA/jN3uPvuu9myZQudOnUiPDyce+65hwkTJgBw2223kZGRQbt27c7L38Op5m7aT52qFejcqPoZ77vnyEkWJR/g5viYAldyz/43gc9X7y5QtmH1ijSLrszBrFyS9h/j1ZFdGNa5Qf72+Nia/P66tvz5601MWpDKfQEN4emoKm//mEqOy8sDAbnyDbuPkn4sx9foLd7O3R+s5KvxfaheKaLY40yck0SViDD+cF1bXB4vI99eym1vL8OritvrC0j/mLOFl3/ZudSriUUpB/AqDGhzqlzLulV5/NrW/OWbRABG92pMtya+NFNs7cp88uterNl5pEA+Pyw0hJHdG/PKvC0M+9ciujauwYrth6gaGc6zw9oTVSmcW7o34sMlO3hsUGvqVI3kgWlrWLHjEK8V+vtWiwxnfP8Wpf49RYThcQ3p2bQWT36+ni37s5g0uivXtq9XYnqnTrVIOsVEMT9xf/53TF6Yyts/bqNvqzrUqRpZ6veeiXIxFYRNY3B6EyZMoEuXLtx1113Fbre/YVH7jmbz0dId/Kp3k6D+p9tz5CR9X/qeCmGhfDm+Ny3qVC223JTF29iSnsVfR3QssP7+j1cxa8M+nh7Sjrsu9903+inlALe+s4xfX9mMYXENSM047nsdyGLbgeMczMrlyevaMKRTgyLfo6pMmLaG/23Yyw1xDfNz0Dd1i6Fns1rFln9h9mb+b0EqIQI//m4ADatXBHwN+hvfp7DqqatJPXCcUZOXEteoOn/7RUeaF7rPsHbXEW54YzEPX90q/4Zr+rFsXp6zhRqVI4hvUoO61SL53Yz1JOzJZFzf5jx6TasCeflAj326jjmb9rPqqYEFyni9yq/eW05qRhazH7qSapGlp7pO5nqYtGAry7YdZO2uI2S7vLw+qgtD/Y37rkMn6PvS99x9RTOyXR4+WLKDZ4e1Z0zv2FKPHYyS0rSFvTpvC6/NT2blHwZyItfDwJcXMLBtXd64retZf3dJU0HYFUA5161bNypXrszEiRMv9KlcElSVmev28PSXG8nMdrPn6Ele/mVcqfu9u2gbXoXI8BDumlr8L+QDWTm8+G0SJ3I93N6rCW3r+3K8B7NymLtpP5UiQvnbrEQ6xUTRsWEUf/hyI7G1KvHQ1a2IDA8N+gYs+H59/v0Xncg86WJpqq9b4ZGTLlZsP8S8h/sWaExVlb/9bzOTF6YyrHMDvl6/h2nLdvLota0B35VNfGxNalSOoFvlCF68qROPz1jPVRN9DdOY3k1oUrMy1SuH89K3m6lVOYI7Lz81uWCdqpG88ItOBc5vxn29/VcoW0lJz+LN27oSEVYwCKgqC5MzuLxF7SIBIiREmDK2O9lub376pDQVI0J56OpWQF630Zz8IAfQqGYlrutYn3cXbcPjVe69slmZNf4Q/LQrA9vW5dV5yXyflMGchH2EiPCH68/NDzQLAOXcqlVn/Swex8l2eXjk03V8s34vXRtXJ7ZWZb5Ys5txfZvTqm7xv+gBDh/PZdrynQzv3IDbejVh1OSljP/3aqaO7VGg4Zq8MJVsl4eIsBA+WLKdv93oaxS/WLMbl0eZdk8PHv10HeM/Xs217eux7cBxPrqrJ5HhoWdVnyoVwgr0apm9cR/jPlrFNxv2Mjzu1EP9Js7ZwuSFqYy5rAnPDGvPiVw301fs5DdXtWR/Zjab9x3jqYAG6IYuDbm8ZW0++Gk7HyzdwbzE/QW+9+kh7UptlCPDQ/nriI60rluVP81M4L6PVvHm6K5UCDtV16T9x9ifmVNil8iw0BCqBNnVsrDw0JACjX+ee69sxjcb9nJ9x/o8MajNWR3752rfoBp1q1Xgn/OT2XnoBI8Pak2DYs61LJSLm8CXUhrrYmN/u1M+X72bb9bv5eGrW/HpuN48PaQdlSPCmDinaG+uQFOXbOdErodf921OtyY1+OuNHVmccpCnv0rI//tmHMvhgyXbGR7XkBu7NOSLNbs5ciI3v39550bViY+tyVuju5GZ7eLDpTsY4W9oy8o17erSum5V/vVdCl5/Ln5xygH+9X0KI7s34plh7RERbuvVhANZuXybsC+/cS+cq69dpQIPX9Oan54YwPt3dOelmzrxh+va8sTgNozu1TjocxrTO5bnbujA/M3pjPtwFdmuUze5FyT5ngB4RavzN4VDp5jqfPdIP14bGUdIyIWZKFFEGNCmLjsPnaBp7cr5KcFz4ZIPAJGRkRw8eNAasrOQ9zyAyMiyvbF0qZq2fCdt6lXlgQEtCA0RalSO4J4rmvFtwn7W7jpS7D4nct1M+Wk7A9vWoXU931XCTd1iuL9fc6Yt38lTX27E61X+b8FWct1eHhjQgl9dFku2y8unK9NYl3aULfuzuMXfm6Rt/Wq8dFNnujauXuaX/SEhwvgBLUhOz2J2wj6OnnTx6KfraBZdmT8NbZ+foujbMppGNSvykf/XfYs6VWhau3Kxx6wUEUb/NnW4Ob4R91zZjHF9mxf4FR+M23s14a8jOvJ9UkaBnksLkzNoXbcq9aPOza/fkjStXbnEexLny/Ud6xMi8Oyw9mf89zwTl3wKKCYmhrS0NOx5wWcn74lgF6uDWTlUqxge9KjKs7Uh7Sgbdh/l2WHtC+Rq77qiKVOXbOcf3ybx3h3d2bQ3k/VpR6gcEUaz6Mr8tPUgR064ivS0eeza1ijw1g9bycpxM3vjPkZ0ickfnNUjtiYfLN3O1owsKoaHMrRz/fx9h3ZukH9jsqxd37E+r87dwuvfpTAnYR/px3L4/L7eVIw41ciEhAi39mjC32dvJkTg132D60X0c9zaszFHTuby4uwkujWpwS3dG7Fi22Hu6BN7zr/7YnR5y9qsfvrqEntalZVLPgCEh4fb06zKqRy3h8Gv/Uhs7cpMu6dXgdGUgY6cyCXb5aVeVHBXMj8mZ/D0lxt5Z0x8fm+daSt2UiEshBu6NCxQtkqFMO7v15y/fJNIx2e+JcdddKKuHrE1iwx0EhEev7Y1IQJvfL+V0BDhN1ed6jo4pncs4/+9mv8c3sWNXWKoGkQvlrIQGiLc378Fj366jsS9mTw4sGWx3VZ/GR/DK3O3kOvxMjCIgV9l4b6+zVm94wjPf5PIgawccj1ermzp3OeAn+vGH8pBADDl1/zEdNKP5ZB+LIfXv0vmwYGtipTxepXb313OjoPH+XJ8n6CmP3j7x21sP3iCCf9ew5fj++DxKl+t2c2QTg2KHTk7ulcTEvceI6piOPGxNYhrVJ2TLg+pGcfZcfA4/f2DdwoTER69pjW1q1QgRIQmtU6lUa5pX5d61SLZl5nNLd0bFbv/uTI8rgFv/pBCVMWS+7PXqlKBYXEN+CnlAHFnMa7hbIgIE3/ZmaGvL+KN77dSMTyU+NifN42EOT0LAKZMHM9x8+nKXaQfy+HwCRdhIcKDA1tSq0qFUvdVVb5PSqdbk5oFGuDPVqVRr1okPZvV5J/zk7msWa0ifdj/t3EfG3YfJSI0hLs/WMkX9/c57fQH+45msyg5g17NarI09RB/m5VI2/rVOJ7r4daexd+8jAwPZeIvOxdZX7gPfHFEhLF9il6hhoeG8ODAlsxLTKf7eW7kwkNDmDnhciqEhZw2tfaXGzqQ7fKUeOV1LkRVDOet0V258c2f6N281ln3gDLBsQBgysRfvklk2vKdhIUI1StFkHnSxeKUA3xwVw9ialQqcT9V5S/fJPLuom1c7x+SD74JsxZsyeDXVzbj/v4tWLfrCA/+Zy2zfnMFNSr7Lo3dHi8T5ybRqm4Vnh3WgdvfXcZvpq3hvTu6l9hofb4mDa/C33/RiQ+W7ODdRduoXaUCretWpWvj8/NLN8/IHo0Z2SP4HjNlKZi+85HhoRekAW7fIIov7u9DjcrnJy3mZJd8LyBz4e05cpLPVu3itp6NSX5+MCufGsjH9/QkIyuHX7z1E1tKmDtGVfnz15t4d9E2Wtapwjfr97J8m28Ooy/W7MbjVX7RLYYqFcJ4fVRXDmTlcO+HKznsn/Vyxuo0UjOO88g1rbmseS3+PLwDC7Zk8NdZicX2ClNVPluZRo/YmjSpVZnHB7WmQ8NqHMjKYVSPRvZ85ItIuwbVznvvHycKKgCIyCARSRKRFBF5opjtj4nIWv9ro4h4RKSmiESKyHIRWSciCSLybMA+z4jI7oD9rivLipnzZ/LCVFThvn7N8xvR7rE1+XTcZajCzZOWFOlG6fUqz8xM4P3F27mzT1NmTric+lGR/PnrBLxe5bNVaXRtXD0/zdIxJoqJv4xjXdpRbnhzMQl7jvLqvGQ6N6rONe18Nylv7dmYO3rH8u6ibfxjTlKRILB65xFSDxznpm6+Xk8VwkJ589Zu3NmnKTfFn988vDEXg1IDgIiEAm8Ag4F2wCgRKTCrmKq+pKpxqhoHPAksUNVDQA4wQFU7A3HAIBHpFbDrK3n7qeqsMqqTOY/Sj2UzbflObuzasEiqp029asy4rzdRFcO5/Z1lrNnpm/n0RK6b+z9ezdQlO7jniqY8PaQtFSNCeWJwGzbuzuRPMxNITs/ipm4FG+VhnRsw7Z5eHM9xM/T1Rew9ms3j17Yu8Mv9j0PaMapHY974fit/n10wCHy2Ko2K4aFc1+lUl8vGtSrxx6Glj1w1pjwK5gqgB5CiqqmqmgtMB4afpvwoYBqA+uRNaxnuf9mIrXMkK8fNg9PXsP3A8SLbztVAubcXpuLyeLm/X/G9SRrVrMT0e3tRs0oEt7+7nP9t2MvNk5bw7aZ9PHV9W35/Xdv8BnxY5wZ0aVydD5fuoEJYCEMC+sbn6dakBl+O70OHhlFc3a4ufQo96DskRHj+hg6M7tWYSQu28uTnG1iaepDDx3P5et0eBneoZ429MX7BBICGwK6A5TT/uiJEpBIwCJgRsC5URNYC6cBcVV0WsMsEEVkvIu+JiPX3+pn+t2EvX67dwyvzthRYf/h4Lj3/Op8Plwb/YGyPV0t9OPWBrBw+WrqT4XENiS1hpChAg+oVmX5vL2pXieC+j1ez/cBx3h0Tz91XNCvw611E+OMQ38Xlte3rlTjDY0yNSsyccDmTb+9W7PaQEOG54R24s09Tpq/YxcjJS+n6l7kcy3Hnp3+MMcH1AiruzlhJPyeHAov96R9fQVUPECci1YEvRKSDqm4E3gKe8x/rOWAicGeRLxe5F7gXoHHjC9Nj4lLxv437APjvuj08cnVrGtfypWQmLdhK+rEc3l6Yym09GheY42TdriNUqxheYKj/wawcRr+7HIAZ911GpYhT/0wWpxzgnR9TST1wnF2HTqDA+P6ljxStH1WR6fdexuvfJXP7ZU1KfNpRl8Y1eP+O7gWeylSS0920FRH+OLQdDwxoweqdh1m14zA5bi+9ipkK2RinCuYKIA0ITMbGAHtKKDsSf/qnMFU9AvyA7woBVd2vqh5V9QJv40s1FbffZFWNV9X46GjnjgosTWa2ix+TMxjauQGhIcLkH7cCvn7vU37aTkyNiuw8dIKFyaemzEjPzOaWyUsY/NrC/OedZhzLYdTbS0nNyGLzvkye/HxDfvpozc7D3DV1BUn7jtGhYRQT+rdg2j29Spz7vrB6UZE8P6JjqY+669+mDnWrlc38RDUqR3BV27o8PqgNTw9pd8Em+DLmYhTMFcAKoKWINAV242vkby1cSESigL7A6IB10YBLVY+ISEVgIPB3/7b6qrrXX3QEsPHnVMTp5m3aj8ujjO0TS6XwUD5ZmcZvr2rF698l41Vl6p09uOX/lvDR0p30a+0bufr6dym4PUpco+o8+uk6lqYeZN2uI6QdPsn7Y7uzavthJs7dQnyTGlzZKpq7p64kumoFvri/D7WDGOBljLm4lRoAVNUtIhOAb4FQ4D1VTRCRcf7tk/xFRwBzVDXwDmR9YKq/J1EI8Imqfu3f9qKIxOFLAW0Hfl0WFSqvlmw9yMrthxjXr3mxozdnbdhH/ahI4mKqU71iOJ+s2sWfv97E/zbsZVSPxjSPrsIv4xsxacFWdh85icejTFu+k1u6N+LZYe15dV4y//o+hUoRobw/tju9mtWiV9NarN55mD9/vYm61SLxqDJlbA9r/I0pJ4LqDuHvojmr0LpJhZanAFMKrVsPdCnhmLefwXk61sbdR3nx2yQWbvGlbqpVDC/ylKJj2S4WJmdwW09ffr9ZdBUGd6jHf9ftITI8hAcG+HrojOrRmLcWbGX68p3sPnzSP0FZS8JCQ3j02tb0bxNN5Qph+SmakBDhlVviGPL6ItKP5fDx3T2Dmv7AGHNpsP5wF6Fsl4c5m/bz6cpd/Jh8gOqVwvnDdW35bnM6r8zbwvC4BgVmCvxuczq5bi/XdzzVbfK+vi2YtWEfY/s0pY4/n96oZiX6t67DB0t2kJnt4t4rmhXItRee0RJ8MxLOuK83R0648ue7N8aUDxYAzrGtGVlUiwwnumpwaZM5Cft49NN1ZGa7aVi9Ig8NbMXYy2OpFhnO5S1rc/0/f+TVeck8M6x9/j7/27CPOlUr0LXxqZ60HWOi+OY3lxd5lOHoXo35bnM6VSuEMS7Ied7rVosss5uyxpiLhwWAnyEz20XVCmHFdkdUVd7+MZW/z06iXf1qzJzQp9S5ZlweL8/+dxP1oiJ5a3R7LmtWq0Cvlbb1qzGyR2M+XLqD0b0a06JOVdIzs/lhSzq3xDcq0sOluIeI921Vh8ua1WJwx3r5k6oZY5zJAsBZWp92hJsnLaF/6zq8OjKuwKyJR0+4eOTTdcxL3E+belXZsPsoszfuY3BAiuZErhuXW4mqdGqw0xdrdrP7yEnev6N7kRGueR65uhX/XbuH383YQK3KEXy3OR0FRnQNboBTaIgw7d5epRc0xpR7NhvoWTiW7eKBaWuIDA9ldsI+7nh/OceyXbg9Xj5ZsYtrX13ID0np/HFIO75+4HJa1KnCP+Yk4faPrM3MdjHsX4sZ+MoC9h49CfimNn7z+xQ6NKxGv9Ylj3eoVaUCvx3YklU7DrN65xHuvLwps397xXl7aIcxpvywK4Cz8MevEth16ATT772MPUdO8uin67h50hLcXiUlPYvOMVG8NborXfw5+UevacW4j1bz+Zrd/KJrDA9OX8v2A8epEBbCvR+s4tNxlzF74z62HzzBpNHdSk0V3XV5U3o2rUWb+lXP+bNyjTHllwWAMzRjVRpfrNnNQwNb0aOpr9dM9Urh3PfRaupXj2TS6K5c275egUb82vb16BwTxWvzkknad4zvNqfz3A0dqF8tkns+XMljn60ncW8mretWzZ/a+HREhI4xRfP7xhhzJuRczRJ5LsTHx+vKlSvPybGPZbuYk7CfG7o0LPFpUunHsun30g90aBhV5CHlmdkuKkeElbjvouQDjH7XNw/ebT0b8/yIjgC8+UMKL85OAuCfo7owrHODsqyWMcYgIqtUNb7wersC8PtyzW6e/iqBjKycErtH/mf5Lk7kenjhxo5FGvqSZq7M06dFLQZ3qEeu21ugC+d9fZuz69AJkvdnFejHb4wx55oFAL+EPZkAvDxnC31bRdO2fsEJy9weL/9evsULAJYAABUASURBVJMrWtam2VmMhhUR3ryta5H8vojwtxs7oar2SEJjzHlldxD9Nu3NpEPDalSrGM5D/1lLjttTYPt3m9PZezSb23o2OevvKG36YmOMOZ8sAOD7db953zEua1aLF2/qyOZ9x3h5bsGHqny0bCf1qkUysG2dC3SWxhhTtiwAAKkHjpPr9tKuQTUGtKnLqB6NmbwwlX8v2wnAjoPHWbglg5E9GhFm3S6NMeWE3QMANvnz/+3q+7pWPj2kLXuPnuT3X2wgOf0YISKEhggju9sTyYwx5YcFACBhz1EiwkJoFu17LGKliDDeHdOd579J5L3F2wAY3KEe9aJsQjRjTPlh+Qx8N4Bb1y04qjY0xPdM2b+O6EiNSuHcfUXTC3iGxhhT9hx/BaCqbNqTyTXt6hW7/daejRnVo5H10jHGlDuOvwLYl5nN4RMu2jcs+UHl1vgbY8ojxweAUzeASw4AxhhTHlkA8AeANhYAjDEOYwFgbyaxtSpRpYLjb4cYYxwmqAAgIoNEJElEUkTkiWK2PyYia/2vjSLiEZGaIhIpIstFZJ2IJIjIswH71BSRuSKS7H+vUfi458OmvZm0a2C//o0xzlNqABCRUOANYDDQDhglIu0Cy6jqS6oap6pxwJPAAlU9BOQAA1S1MxAHDBKRvOcRPgHMV9WWwHz/8nl1LNvFjoMnLP9vjHGkYK4AegApqpqqqrnAdGD4acqPAqYBqE+Wf324/5X3AILhwFT/56nADWd47j/b5n3HAOwKwBjjSMEEgIbAroDlNP+6IkSkEjAImBGwLlRE1gLpwFxVXebfVFdV9wL438/7LGvzE9OBU1NAGGOMkwQTAIrrBF/SY8SGAov96R9fQVWPPzUUA/QQkQ5ncoIicq+IrBSRlRkZGWey62mt3XWEt39MZUSXhjbFgzHGkYIJAGlAo4DlGGBPCWVH4k//FKaqR4Af8F0hAOwXkfoA/vf0EvabrKrxqhofHR0dxOmW7mSuh4f/s5Y6VSsUeDqXMcY4STABYAXQUkSaikgEvkZ+ZuFCIhIF9AW+ClgXLSLV/Z8rAgOBzf7NM4Ex/s9jAvc71174XyKpB47zj5s7E1Xx9I9yNMaY8qrUzu+q6haRCcC3QCjwnqomiMg4//ZJ/qIjgDmqejxg9/rAVH9PohDgE1X92r/tBeATEbkL2AncXCY1KsWSrQeZumQHY/vE0qdF7fPxlcYYc1EKavSTqs4CZhVaN6nQ8hRgSqF164EuJRzzIHBV8KdaNhalZBAi8LtBbc73VxtjzEXFcSOBXR4lIiyEyPDQC30qxhhzQTkwAHgJD3FctY0xpgjHtYQuj5fwMMdV2xhjinBcS+j2KOGhNr+/McY4LgDkeryEWQrIGGOcFwDybgIbY4zTOa4ldHu8hIVYCsgYYxwXAFweL+Ghjqu2McYU4biW0OVR6wVkjDE4MgB4CbcUkDHGODQAWArIGGOcGACUMBsHYIwxTgwAXiLsCsAYY5wXANx2BWCMMYADA4DdAzDGGB/HtYQur6WAjDEGnBgA3JYCMsYYcGIAsBSQMcYAFgCMMcaxHNcSuux5AMYYAzgwALi9dgVgjDEQZAAQkUEikiQiKSLyRDHbHxORtf7XRhHxiEhNEWkkIt+LSKKIJIjIbwP2eUZEdgfsd11ZVqw4quofCWwBwBhjwkorICKhwBvA1UAasEJEZqrqprwyqvoS8JK//FDgIVU9JCIVgEdUdbWIVAVWicjcgH1fUdV/lHGdSuTyKAARlgIyxpigrgB6ACmqmqqqucB0YPhpyo8CpgGo6l5VXe3/fAxIBBr+vFM+e26vF8CuAIwxhuACQENgV8ByGiU04iJSCRgEzChmWyzQBVgWsHqCiKwXkfdEpEaQ53zWXG7fFYDdAzDGmOACQHH5Ei2h7FBgsaoeKnAAkSr4gsKDqprpX/0W0ByIA/YCE4v9cpF7RWSliKzMyMgI4nRL5vJfAVgKyBhjggsAaUCjgOUYYE8JZUfiT//kEZFwfI3/x6r6ed56Vd2vqh5V9QJv40s1FaGqk1U1XlXjo6Ojgzjdkrk8lgIyxpg8wbSEK4CWItJURCLwNfIzCxcSkSigL/BVwDoB3gUSVfXlQuXrByyOADae+emfGUsBGWPMKaX2AlJVt4hMAL4FQoH3VDVBRMb5t0/yFx0BzFHV4wG79wFuBzaIyFr/ut+r6izgRRGJw5dO2g78uiwqdDp5KSAbCGaMMUEEAAB/gz2r0LpJhZanAFMKrVtE8fcQUNXbz+A8y0ReCsiuAIwxxmEjgd3+cQBh9lB4Y4xxVgDIzbsCCHNUtY0xpliOagnd+SOBHVVtY4wplqNawvxuoJYCMsYYZwUASwEZY8wpjmoJ81JA4SGOqrYxxhTLUS1hfjfQMEsBGWOMMwOA3QQ2xhinBQBLARljTB5HtYSWAjLGmFMcFQDc+d1AHVVtY4wplqNawlwbCGaMMfkc1RK6LQVkjDH5HBUAXJYCMsaYfI5qCfNSQPY8AGOMcVgAcHu8hIUIvgeVGWOMszkqALg8XhsEZowxfo5qDV0etfSPMcb4OSwA2BWAMcbkcVRr6PaoBQBjjPFzVGvo8ngJsxSQMcYADgsAuR6vjQI2xhi/oFpDERkkIkkikiIiTxSz/TERWet/bRQRj4jUFJFGIvK9iCSKSIKI/DZgn5oiMldEkv3vNcqyYsVxe9SuAIwxxq/UACAiocAbwGCgHTBKRNoFllHVl1Q1TlXjgCeBBap6CHADj6hqW6AXMD5g3yeA+araEpjvXz6n7CawMcacEkxr2ANIUdVUVc0FpgPDT1N+FDANQFX3qupq/+djQCLQ0F9uODDV/3kqcMOZn/6ZcXntJrAxxuQJpjVsCOwKWE7jVCNegIhUAgYBM4rZFgt0AZb5V9VV1b3gCxRAnRKOea+IrBSRlRkZGUGcbslcbq+NAzDGGL9gAkBxLaaWUHYosNif/jl1AJEq+ILCg6qaeSYnqKqTVTVeVeOjo6PPZNciLAVkjDGnBNMapgGNApZjgD0llB2JP/2TR0TC8TX+H6vq5wGb9otIfX+Z+kB6sCd9tlxeJcwCgDHGAMEFgBVASxFpKiIR+Br5mYULiUgU0Bf4KmCdAO8Ciar6cqFdZgJj/J/HBO53rrjcXiIsBWSMMUAQAUBV3cAE4Ft8N3E/UdUEERknIuMCio4A5qjq8YB1fYDbgQEB3USv8297AbhaRJKBq/3L55TbaykgY4zJExZMIVWdBcwqtG5SoeUpwJRC6xZR/D0EVPUgcFXwp/rzuTyWAjLGmDyOag19N4EtBWSMMeDEAGCPgzTGGMBxAUDtgfDGGOPnsABgN4GNMSaPo1pDCwDGGHOKo1pDtz0S0hhj8jkmAHi9iturhNlNYGOMARwUAFxeLwARYY6psjHGnJZjWkO3xzd/XViIpYCMMQYcFABcHt8VgN0ENsYYH8e0hi7/FUC4pYCMMQZwVADwXwFYCsgYYwAnBgBLARljDOCoAOC/CWzjAIwxBnBUAPB3A7UrAGOMARwUAPK6gVoKyBhjfBzTGub6rwAsBWSMMT6OCQBuSwEZY0wBjmkNT90EdkyVjTHmtBzTGp7qBmopIGOMAUcGAMdU2RhjTiuo1lBEBolIkoikiMgTxWx/TETW+l8bRcQjIjX9294TkXQR2Vhon2dEZHfAfteVTZWK57JeQMYYU0CpraGIhAJvAIOBdsAoEWkXWEZVX1LVOFWNA54EFqjqIf/mKcCgEg7/St5+qjrrbCsRDLfXUkDGGBMomJ/DPYAUVU1V1VxgOjD8NOVHAdPyFlR1IXCo5OLnR67bUkDGGBMomNawIbArYDnNv64IEamE79f+jCC/f4KIrPeniWqUcMx7RWSliKzMyMgI8rBFWQrIGGMKCqY1LC5noiWUHQosDkj/nM5bQHMgDtgLTCyukKpOVtV4VY2Pjo4O4rDFy0sB2UAwY4zxCSYApAGNApZjgD0llB1JQPrndFR1v6p6VNULvI0v1XTOWArIGGMKCqY1XAG0FJGmIhKBr5GfWbiQiEQBfYGvgvliEakfsDgC2FhS2bLg9vouWmwksDHG+JTaGqqqG5gAfAskAp+oaoKIjBORcQFFRwBzVPV44P4iMg1YArQWkTQRucu/6UUR2SAi64H+wENlUJ8SudyWAjLGmEBhwRTyd9GcVWjdpELLU/B1+Sy876gSjnl7sCdZFvIGgtlD4Y0xxscx+RCXVwkPFUQsABhjDDgpALi9dgPYGGMCOKZFdHvVAoAxxgRwTIuY6/HaNBDGGBPAMQHA7bEUkDHGBHJMi+jyqHUBNcaYAI4JALl2BWCMMQU4pkV0e7w2CtgYYwI4pkW0FJAxxhTkoABgKSBjjAnkmBbR5fESHuKY6hpjTKkc0yK6PEp4mKWAjDEmj2MCgNvjJcyuAIwxJp9jWsRcj00FYYwxgRzTIro9XiIsBWSMMfkcEwBclgIyxpgCHNMiuiwFZIwxBTimRXTZbKDGGFOAwwKAY6prjDGlckyL6LYUkDHGFOCYFtEeCGOMMQUFFQBEZJCIJIlIiog8Ucz2x0Rkrf+1UUQ8IlLTv+09EUkXkY2F9qkpInNFJNn/XqNsqlQ8eySkMcYUVGqLKCKhwBvAYKAdMEpE2gWWUdWXVDVOVeOAJ4EFqnrIv3kKMKiYQz8BzFfVlsB8//I54fEqHq/NBmqMMYGC+UncA0hR1VRVzQWmA8NPU34UMC1vQVUXAoeKKTccmOr/PBW4IagzPgsujxfArgCMMSZAMC1iQ2BXwHKaf10RIlIJ36/9GUEct66q7gXwv9cp4Zj3ishKEVmZkZERxGGLcnsVwB4IY4wxAYJpEYvLm2gJZYcCiwPSPz+bqk5W1XhVjY+Ojj6rY7jcvisASwEZY8wpwQSANKBRwHIMsKeEsiMJSP+UYr+I1Afwv6cHud8Zc3ktBWSMMYUF0yKuAFqKSFMRicDXyM8sXEhEooC+wFdBfvdMYIz/85gz2O+MuTy+CxbrBmqMMaeUGgBU1Q1MAL4FEoFPVDVBRMaJyLiAoiOAOap6PHB/EZkGLAFai0iaiNzl3/QCcLWIJANX+5fPibwUkF0BGGPMKWHBFFLVWcCsQusmFVqegq/LZ+F9R5VwzIPAVUGe58/i9ubdA7AAYIwxeRzRIua683oBWQrIGGPyOCIAuO0msDHGFOGIFjFvIJilgIwx5hRHtIjWC8gYY4pySACwFJAxxhTmiBbRAoAxxhTliBbRUkDGGFOUQwKAXQEYY0xhjmgR3flXAI6orjHGBMURLWJuXjfQEEsBGWNMHkcEgLwUUESYI6prjDFBcUSLaCkgY4wpyhEt4qmRwJYCMsaYPA4JAPZISGOMKcwRLaLLbgIbY0wRjgkAIhBqAcAYY/I5JAAo4aEhiFgAMMaYPA4JAF7C7de/McYU4IgA4PZ4CbcxAMYYU0BQzwS+1LWtX42TLs+FPg1jjLmoOCIAjOzRmJE9Gl/o0zDGmItKUHkRERkkIkkikiIiTxSz/TERWet/bRQRj4jUPN2+IvKMiOwO2O+6squWMcaY0pQaAEQkFHgDGAy0A0aJSLvAMqr6kqrGqWoc8CSwQFUPBbHvK3n7qeqsMqqTMcaYIARzBdADSFHVVFXNBaYDw09TfhQw7Sz3NcYYc54EEwAaArsCltP864oQkUrAIGBGkPtOEJH1IvKeiNQo4Zj3ishKEVmZkZERxOkaY4wJRjABoLgO9FpC2aHAYlU9FMS+bwHNgThgLzCxuAOq6mRVjVfV+Ojo6CBO1xhjTDCCCQBpQKOA5RhgTwllR3Iq/XPafVV1v6p6VNULvI0vXWSMMeY8CSYArABaikhTEYnA18jPLFxIRKKAvsBXwewrIvUDyo0ANp5dFYwxxpyNUscBqKpbRCYA3wKhwHuqmiAi4/zbJ/mLjgDmqOrx0vb1b35RROLwpYS2A78uozoZY4wJgqiWlM6/+IhIBrDjDHapDRw4R6dzMXNivZ1YZ3BmvZ1YZ/h59W6iqkVuol5SAeBMichKVY2/0Odxvjmx3k6sMziz3k6sM5ybetsMacYY41AWAIwxxqHKewCYfKFP4AJxYr2dWGdwZr2dWGc4B/Uu1/cAjDHGlKy8XwEYY4wpQbkNAKVNYV0eiEgjEfleRBJFJEFEfutfX1NE5opIsv+92HmWLmUiEioia0Tka/+yE+pcXUQ+E5HN/v/ml5X3eovIQ/5/2xtFZJqIRJbHOvvnQ0sXkY0B60qsp4g86W/bkkTk2rP93nIZAIKZwrqccAOPqGpboBcw3l/PJ4D5qtoSmO9fLm9+CyQGLDuhzq8Bs1W1DdAZX/3Lbb1FpCHwGyBeVTvgG0w6kvJZ5yn4JtIMVGw9/f+PjwTa+/d509/mnbFyGQBwyDTUqrpXVVf7Px/D1yA0xFfXqf5iU4EbLswZnhsiEgNcD7wTsLq817kacCXwLoCq5qrqEcp5vfHNVlBRRMKASvjmEit3dVbVhcChQqtLqudwYLqq5qjqNiCFs5xLrbwGgKCnsC4vRCQW6AIsA+qq6l7wBQmgzoU7s3PiVeBxwBuwrrzXuRmQAbzvT329IyKVKcf1VtXdwD+AnfhmDD6qqnMox3UupKR6lln7Vl4DwJlMYX3JE5Eq+J7B8KCqZl7o8zmXRGQIkK6qqy70uZxnYUBX4C1V7QIcp3ykPkrkz3kPB5oCDYDKIjL6wp7VRaHM2rfyGgDOZArrS5qIhONr/D9W1c/9q/fnzbbqf0+/UOd3DvQBhonIdnypvQEi8hHlu87g+zedpqrL/Muf4QsI5bneA4Ftqpqhqi7gc6A35bvOgUqqZ5m1b+U1AAQ1hfWlTkQEX044UVVfDtg0Exjj/zyGglN0X9JU9UlVjVHVWHz/Xb9T1dGU4zoDqOo+YJeItPavugrYRPmu906gl4hU8v9bvwrffa7yXOdAJdVzJjBSRCqISFOgJbD8rL5BVcvlC7gO2AJsBf5woc/nHNXxcnyXfuuBtf7XdUAtfL0Gkv3vNS/0uZ6j+vcDvvZ/Lvd1xvf0vJX+/95fAjXKe72BZ4HN+J4X8iFQoTzWGd+DtPYCLny/8O86XT2BP/jbtiRg8Nl+r40ENsYYhyqvKSBjjDGlsABgjDEOZQHAGGMcygKAMcY4lAUAY4xxKAsAxhjjUBYAjDHGoSwAGGOMQ/0/vxsRmVQDh3QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the accuracy\n",
    "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "# nn.save('Models/AlphabetSoupCharity2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "<b>This is Attempt #2</b>\n",
    "<br>APPLICATION_TYPE cutoff = 600\n",
    "<br>CLASSIFICATION cutoff = 300\n",
    "<br>layer1 = 9 : activation function = relu\n",
    "<br>layer2 = 18 : activation function = relu\n",
    "<br>layer3 = 27 : activation function = relu\n",
    "\n",
    "Loss: 0.5534283416889847, Accuracy: 0.7258309125900269\n",
    "\n",
    "A loss value of 55 indicates that the model can be further optimized. \n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "Still not at 75% accuracy. Will try something drastic next.\n",
    "\n",
    "-----\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "\n",
    "<br>APPLICATION_TYPE cutoff = 600\n",
    "<br>CLASSIFICATION cutoff = 300\n",
    "<br>layer1 = 12\n",
    "<br>layer2 = 24\n",
    "<br>layer3 = 36\n",
    "\n",
    "Loss: 0.5545361445735565, Accuracy: 0.7241982221603394\n",
    "\n",
    "\n",
    "<br>APPLICATION_TYPE cutoff = 800\n",
    "<br>CLASSIFICATION cutoff = 1000\n",
    "<br>layer1 = 12\n",
    "<br>layer2 = 24\n",
    "<br>layer3 = 36\n",
    "\n",
    "Loss: \n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt #3 -- changing the activation functions\n",
    "APPLICATION_TYPE cutoff = 600<br>\n",
    "CLASSIFICATION cutoff = 300<br>\n",
    "layer1 = 9 : activation function = relu<br>\n",
    "layer2 = 18 : activation function = tanh<br>\n",
    "layer3 = 27 : activation function = tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# number_input_features = len(X_train_scaled[0])\n",
    "# hidden_nodes_layer1 = 9\n",
    "# hidden_nodes_layer2 = 18\n",
    "# hidden_nodes_layer3 = 27\n",
    "\n",
    "# nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "# nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "# nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "# y_test = np.array(y_test)\n",
    "# y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "# fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "# model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the accuracy\n",
    "# history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "# history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "# nn.save('Models/AlphabetSoupCharity3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
